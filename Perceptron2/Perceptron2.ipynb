{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjUCSzpv+OY00A0CDMHAKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HakkiAkut/ai-ml-algorithms/blob/master/Perceptron2/Perceptron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3iF4A-wMLba"
      },
      "source": [
        "Implementing single layer perceptron for classifying mnist digit classification dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F222BXoyxCpu"
      },
      "source": [
        "Importing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmVI6XoOw6ZG",
        "outputId": "2b58dded-8874-43fc-d884-eaa750cf80f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "#len(train_X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNPellK_yJOE"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HlwnMp7x_x8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HarllesRfOvw"
      },
      "source": [
        "One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPLFNqIBfOGD"
      },
      "source": [
        "def one_hot_encoding(data):\n",
        "  labelEncoder= LabelEncoder() # label encoder\n",
        "  oneHotEncoder = OneHotEncoder(sparse=False) # one hot encoder\n",
        "  labels_int = labelEncoder.fit_transform(data)\n",
        "  labels_int = labels_int.reshape(len(labels_int), 1)\n",
        "  labels_onehot = oneHotEncoder.fit_transform(labels_int)\n",
        "  return labels_onehot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIraEPkj2yIy"
      },
      "source": [
        "Converting 2d list to 1d for easier implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzS7JMJX0fyw"
      },
      "source": [
        "def change2Dto1D(item):\n",
        "  oneD = np.array(item[0])\n",
        "  for row in item[1:]:\n",
        "    oneD = np.concatenate([oneD, row])\n",
        "  return oneD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXvsi6aZhLVt"
      },
      "source": [
        "data convertion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdqBJbvthG12"
      },
      "source": [
        "def convertingData(data,label):\n",
        "  new_data= np.array([change2Dto1D(item)for item in data])\n",
        "  new_label= one_hot_encoding(label)\n",
        "  return new_data, new_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzoCzizD2wEk"
      },
      "source": [
        "train_X1D,train_y1H= convertingData(train_X[0:20000],train_y[0:20000])\n",
        "test_X1D, test_y1H= convertingData(test_X[0:7000],test_y[0:7000])\n",
        "#train_X1D,train_y1H[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE6ffRW6iOUM"
      },
      "source": [
        "Multi-class Perceptron Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yHhAdOHiNdl"
      },
      "source": [
        "def multiclass_training(features, labels, lr=0.001, iteration=5):\n",
        "  weights=[]\n",
        "  bias=[]\n",
        "  for j in range(len(labels[0])):\n",
        "    weights.append(np.random.rand(features.shape[1])) \n",
        "    bias.append(0.0) \n",
        "\n",
        "  # training the same dataset for 'iteration' times\n",
        "  for i in range(iteration):\n",
        "    index = 0;\n",
        "    #training each row\n",
        "    for sample in features:\n",
        "      pred = multiclass_prediction(sample, weights, bias)\n",
        "      # updating weights and bias for each column\n",
        "      for k in range(len(bias)):\n",
        "        delta_weights= lr*(labels[index][k]- pred[k])\n",
        "        weights[k]+= delta_weights*sample\n",
        "        bias[k] += delta_weights\n",
        "      index+=1\n",
        "  return weights,bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vch7SBqViZXa"
      },
      "source": [
        "Multi-class Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eff7oWk4iRD6"
      },
      "source": [
        "def multiclass_prediction(features, weights, bias):\n",
        "  calculated_inputs=[]\n",
        "  # predicting for each rows of one hot encoded labels value, \n",
        "  for k in range(len(bias)):\n",
        "    calc_inp = np.dot(features, weights[k])+bias[k]\n",
        "    calculated_inputs.append(calc_inp)\n",
        "  gp=0; \n",
        "  # finding greatest probability and changing to one hot encoded type.\n",
        "  for j in range(len(calculated_inputs)):\n",
        "    if calculated_inputs[j] > calculated_inputs[gp]:\n",
        "      gp= j\n",
        "  pred=np.zeros(len(calculated_inputs))\n",
        "  pred[gp]= 1\n",
        "  return pred "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SpkDdcOiiv6"
      },
      "source": [
        "def check_prediction_list(prediction, result):\n",
        "  checked = prediction == result \n",
        "  if type(checked)== bool:\n",
        "    print(checked,prediction,result)\n",
        "    if checked == False:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  else:\n",
        "    if False in checked: \n",
        "      return 1\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BnYOwqhj7jO"
      },
      "source": [
        "def find_metrics(labels,check_list,decision_list):\n",
        "  n = len(check_list)\n",
        "  error=0\n",
        "  label_num= np.zeros(len(labels[0])) # number of real values\n",
        "  label_true= np.zeros(len(labels[0])) # number of true predicts\n",
        "  label_pred= np.zeros(len(labels[0])) # number of predicted values \n",
        "  precision_list= np.zeros(len(labels[0]))\n",
        "  recall_list= np.zeros(len(labels[0]))\n",
        "  # calculating number of real values, true predicts, predicted values \n",
        "  for k in range(n):\n",
        "    index = find_index(labels[k])\n",
        "    label_num[index] = label_num[index] + 1\n",
        "    if check_list[k] == 0:\n",
        "      label_true[index] = label_true[index] + 1\n",
        "      label_pred[index] = label_pred[index] + 1\n",
        "    else:\n",
        "      index_choosed = find_index(decision_list[k])\n",
        "      label_pred[index_choosed] = label_pred[index_choosed] + 1\n",
        "      error +=1\n",
        "  # calculating each precision and recall  \n",
        "  for j in range(len(label_num)):\n",
        "    recall_list[j]= label_true[j]/label_num[j]\n",
        "    precision_list[j]= label_true[j]/label_pred[j]\n",
        "  # calculating average precision and recall \n",
        "  recall_avg= sum(recall_list)/len(recall_list)\n",
        "  precision_avg= sum(precision_list)/len(precision_list)\n",
        "  # printing the metrics\n",
        "  print(f\"average accuracy {(n-error)/n}\") \n",
        "  print(f\"average recall {recall_avg}\")\n",
        "  print(f\"average precision {precision_avg}\")  \n",
        "\n",
        "def find_index(label):\n",
        "  index=0\n",
        "  for k in range(len(label)):\n",
        "    if label[k] == 1:\n",
        "      return k "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv9ZjeETkFP3",
        "outputId": "d1e1e2fe-6fcf-4791-9e50-e8a918273503"
      },
      "source": [
        "weights_trained, bias_trained = multiclass_training(train_X1D, train_y1H, lr=0.01, iteration=50)\n",
        "check_list= []\n",
        "predictions= []\n",
        "error_num= 0\n",
        "\n",
        "zipper = zip(test_X1D, test_y1H)\n",
        "for sample , result in zipper:\n",
        "  prediction_final = multiclass_prediction(sample, weights_trained, bias_trained)\n",
        "  predictions.append(prediction_final)\n",
        "  error = check_prediction_list(prediction_final, result)\n",
        "  check_list.append(error)\n",
        "  error_num = error_num + error\n",
        "\n",
        "find_metrics(train_y1H,check_list,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average accuracy 0.8751428571428571\n",
            "average recall 0.8751727914552431\n",
            "average precision 0.877105360279655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb0TWWpMphe3"
      },
      "source": [
        "average accuracy 0.8751428571428571\n",
        "average recall 0.8751727914552431\n",
        "average precision 0.877105360279655"
      ]
    }
  ]
}