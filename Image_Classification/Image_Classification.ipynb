{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image-Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhXWWCpcA+NVKBvs3lWgWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HakkiAkut/ai-ml-algorithms/blob/master/Image_Classification/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEGFKzdRX9S_"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BisHbnY6CCT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcSU7d1GuO4y"
      },
      "source": [
        "Importing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aqPbbZtVAhS"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "x_train= x_train.astype('float32')\n",
        "x_train= x_train/255\n",
        "x_test= x_test.astype('float32')\n",
        "x_test= x_test/255\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)\n",
        "y_train= to_categorical(y_train)\n",
        "y_test= to_categorical(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-9Kodnw3TsF"
      },
      "source": [
        "initializing constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SAWID6E1Nt9"
      },
      "source": [
        "activation_function = 'relu'\n",
        "num_of_classes = 10 # there is 10 classes in this dataset\n",
        "batch_size=64\n",
        "kernel_size= (3,3)\n",
        "input_shape = (32,32,3)\n",
        "epochs = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AvvpP3z3Zi-"
      },
      "source": [
        "initializing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5yg20tLuT1n"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNUPmbZc4xty"
      },
      "source": [
        "Convolutional Layers\n",
        "\n",
        "Since, in this dataset we try to find objects in images(such as truck, ship etc.) I decided to use this Conv2D layer which is Convolutional layer for 2D inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_khhG5L4xL6"
      },
      "source": [
        "# Layer 1\n",
        "model.add(Conv2D(32,kernel_size =kernel_size, activation= activation_function, input_shape= input_shape, name='layer1'))\n",
        "model.add(BatchNormalization())\n",
        "# Layer 2\n",
        "model.add(Conv2D(32,kernel_size =kernel_size, activation= activation_function, name='layer2'))\n",
        "model.add(BatchNormalization())\n",
        "# Layer 3\n",
        "model.add(Conv2D(64,kernel_size =kernel_size, activation= activation_function, name='layer3'))\n",
        "model.add(BatchNormalization())\n",
        "# Layer 4\n",
        "model.add(Conv2D(64,kernel_size =kernel_size, activation= activation_function, name='layer4'))\n",
        "model.add(BatchNormalization())\n",
        "# Layer 5\n",
        "model.add(Conv2D(64,kernel_size =kernel_size, activation= activation_function, name='layer5'))\n",
        "model.add(BatchNormalization())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9LvQmoo_M9O"
      },
      "source": [
        "Flatten Layer\n",
        "\n",
        "In this layer we change input to linear, since we will use Dense Layer for remaining Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEn4knpb_IM_"
      },
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2qbG80vBBEm"
      },
      "source": [
        "Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dERmsK6SBAWj"
      },
      "source": [
        "# Layer 6\n",
        "model.add(Dense(64,activation= activation_function, name='layer6'))\n",
        "model.add(BatchNormalization())\n",
        "# Layer 7\n",
        "model.add(Dense(64,activation= activation_function, name='layer7'))\n",
        "model.add(BatchNormalization())\n",
        "# Layer 8\n",
        "model.add(Dense(32,activation= activation_function, name='layer8'))\n",
        "model.add(BatchNormalization())\n",
        "# Layer 9\n",
        "model.add(Dense(32,activation= activation_function, name='layer9'))\n",
        "model.add(BatchNormalization())\n",
        "# Layer 10\n",
        "model.add(Dense(16,activation= activation_function, name='layer10'))\n",
        "model.add(BatchNormalization())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMwb9LiSCsG4"
      },
      "source": [
        "Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgOncn56CeYR"
      },
      "source": [
        "model.add(Dense(num_of_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtYsKPsdCy4x"
      },
      "source": [
        "Compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VD3wqzECxsI"
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcV-8gYXEgbV"
      },
      "source": [
        "Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsbnOGw8DI5Y",
        "outputId": "86d49efe-9cad-4ac2-eb4b-e9b81f6ab4ac"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer1 (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_47 (Bat  (None, 30, 30, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " layer2 (Conv2D)             (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_48 (Bat  (None, 28, 28, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " layer3 (Conv2D)             (None, 26, 26, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_49 (Bat  (None, 26, 26, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " layer4 (Conv2D)             (None, 24, 24, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_50 (Bat  (None, 24, 24, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " layer5 (Conv2D)             (None, 22, 22, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_51 (Bat  (None, 22, 22, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 30976)             0         \n",
            "                                                                 \n",
            " layer6 (Dense)              (None, 64)                1982528   \n",
            "                                                                 \n",
            " batch_normalization_52 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " layer7 (Dense)              (None, 64)                4160      \n",
            "                                                                 \n",
            " batch_normalization_53 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " layer8 (Dense)              (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_54 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " layer9 (Dense)              (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_55 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " layer10 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " batch_normalization_56 (Bat  (None, 16)               64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,094,874\n",
            "Trainable params: 2,093,946\n",
            "Non-trainable params: 928\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e8WnMbDFX7K"
      },
      "source": [
        "Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sp62VGKEjHv",
        "outputId": "0b2a9e4d-2e3f-4abd-953d-1bbc5c0034c6"
      },
      "source": [
        "model.fit(x_train,y_train, epochs=epochs,validation_data=(x_test,y_test),batch_size=batch_size,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "782/782 [==============================] - 610s 778ms/step - loss: 1.6161 - accuracy: 0.4210 - val_loss: 1.8261 - val_accuracy: 0.3818\n",
            "Epoch 2/6\n",
            "782/782 [==============================] - 601s 768ms/step - loss: 1.1128 - accuracy: 0.6112 - val_loss: 0.9731 - val_accuracy: 0.6585\n",
            "Epoch 3/6\n",
            "782/782 [==============================] - 599s 766ms/step - loss: 0.8992 - accuracy: 0.6889 - val_loss: 1.0475 - val_accuracy: 0.6385\n",
            "Epoch 4/6\n",
            "782/782 [==============================] - 600s 768ms/step - loss: 0.7530 - accuracy: 0.7417 - val_loss: 0.9732 - val_accuracy: 0.6656\n",
            "Epoch 5/6\n",
            "782/782 [==============================] - 597s 763ms/step - loss: 0.6359 - accuracy: 0.7821 - val_loss: 0.8252 - val_accuracy: 0.7288\n",
            "Epoch 6/6\n",
            "782/782 [==============================] - 588s 752ms/step - loss: 0.5224 - accuracy: 0.8218 - val_loss: 0.9427 - val_accuracy: 0.7015\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4bf2f25410>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E2I_ePPXz4K"
      },
      "source": [
        "Loss and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCTpNPgRXQVA",
        "outputId": "5a1c5ba3-41b0-4fab-8dcc-f0ebd7fe8c53"
      },
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(f'loss: {loss}, accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 27s 171ms/step - loss: 0.9427 - accuracy: 0.7015\n",
            "loss: 0.9427400231361389, accuracy: 0.7014999985694885\n"
          ]
        }
      ]
    }
  ]
}